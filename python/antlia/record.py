#!/usr/bin/env python
# -*- coding: utf-8 -*-
import glob
import itertools
import os
import pickle
import warnings

import h5py
import numpy as np
import numpy.testing as npt
import scipy.signal
import matplotlib.pyplot as plt
import seaborn as sns

from antlia.util import reduce_runs
from antlia.trial import Trial
from antlia import trial2
from antlia.trial2 import Trial2
from antlia.lidar import LidarRecord
from antlia.dtype import LIDAR_ANGLES, LIDAR_RECORD_DTYPE, LIDAR_CONVERTED_DTYPE


def load_file(filename, calibration_dict=None):
    if filename.endswith('.csv'):
        data = load_etrike(filename)
        return convert_etrike(data, calibration_dict)
    elif filename.endswith('.h5'):
        data = load_imuwnet(filename)
        r = convert_imuwnet(data)
        for d in data:
            try:
                d.close()
            except AttributeError:
                pass
        return r


def load_etrike(filename):
    # steer angle and speed are sampled as integer types but we later convert
    # them to floats for plotting
    return np.recfromcsv(filename, delimiter=',', dtype=np.float64,
                         invalid_raise=False)


def convert_etrike(record, calibration_dict):
    """ Convert record fields from sampled unit to SI unit using provided
        calibration_dict generated by calibrate.py.
        This function is idempotent as is uses the names of the record fields
        to determine if conversion should occur.

        Returns True if conversion is performed.
    """
    names = list(record.dtype.names)
    newnames = ['time']
    if names[0] == newnames[0]:
        return record

    for name in names[1:]:
        if name.startswith('acc'):
            newname = 'accelerometer ' + name[3]
        elif name.startswith('gyro'):
            newname = 'gyroscope ' + name[4]
        elif name == 'steerangle_lsb':
            newname = 'steer angle'
        elif name == 'speed_lsb':
            newname = 'speed'
        elif name == 'flag_bool':
            newname = 'sync'
        else:
            raise ValueError(
                'conversion for signal {} is not defined'.format(name))
        # Conversion assumes linear relationship incorporates both calibration
        # and unit conversion.
        # 'flag_bool/sync' has no unit conversion
        if name == 'flag_bool':
            # flip sync value to be active high
            record[name] = np.invert(record[name].astype(bool)).astype(
                    record[name].dtype)
        else:
            record[name] = np.polyval(calibration_dict[newname],
                                      record[name])
        newnames.append(newname)

    record.dtype.names = newnames
    return record


def load_imuwnet(filename):
    """ Data from Cain, 2016, Measurement of bicycle and rider kinematics during
    real-world cycling using a wireless array of inertial sensors.
    """
    # 'raw' imu data
    f = h5py.File(filename, 'r')
    try:
        # mat file with calculated speed, steer angle, etc.
        g = h5py.File(filename + '.mat', 'r')
    except OSError:
        g = None
    return (f, g)


def convert_imuwnet(data):
    f, g = data

    # frame data corresponds to imu SI-002767
    dataset = f['SI-002767']
    acc = dataset['Calibrated/Accelerometers'].value
    gyro = dataset['Calibrated/Gyroscopes'].value
    t = dataset['Time'].value.flatten()
    t -= t[0] # redefine first sample to be at time zero
    t = t.astype(np.float) # convert from unsigned integer to floating type
    t /= 1000000 # convert microseconds to seconds

    names = ['time',
             'accelerometer x',
             'accelerometer y',
             'accelerometer z',
             'gyroscope x',
             'gyroscope y',
             'gyroscope z']
    split = lambda x: [y.flatten() for y in np.split(x, 3, axis=1)]
    signals = [t] + split(acc) + split(gyro)

    if g is not None:
        names = names[:1] + ['steer angle', 'speed'] + names[1:]
        g_signals = [g['data/{}'.format(s)].value.flatten()
                     for s in ['steer_angle', 'speed']]
        signals = signals[:1] + g_signals + signals[1:]

    r = np.rec.fromarrays(signals, names=names)
    return r


def __get_record_files(extension):
    record_path = os.path.join(os.path.dirname(__file__),
                               r'../../data/lidar/')
    return sorted(glob.glob('{}*{}'.format(record_path, extension)))


LIDAR_RECORD_FILES =  __get_record_files('.bin')
BICYCLE_RECORD_FILES = __get_record_files('.csv')
assert LIDAR_RECORD_FILES, "No LIDAR records found!"
assert BICYCLE_RECORD_FILES, "No bicycle records found!"


def _get_lidar_records(convert_dtype=True, index=None):
    """Returns a list of LIDAR records.

    Parameters:
    convert_dtype: bool, Datatype of LIDAR records.
                   True    - dtype = LIDAR_CONVERTED_DTYPE
                   False   - dtype = LIDAR_RECORD_DTYPE
    Returns:
    records: list of array_like
    """
    float_dtype = np.dtype(','.join(len(LIDAR_RECORD_DTYPE) * ['f8']))

    records = []
    if index is None:
        index = slice(None)
    else:
        index = slice(index, index + 1)

    for filename in LIDAR_RECORD_FILES[index]:
        with open(filename, 'rb') as f:
            x = np.fromfile(f, LIDAR_RECORD_DTYPE)
            if convert_dtype:
                # copy and convert data to new dtype
                y = x.astype(float_dtype)
                # create view which shares the same underlying memory
                x = y.view(LIDAR_CONVERTED_DTYPE).view(np.recarray)
                # convert timestamp to time and start at zero
                x.time /= 1000
                x.time -= x.time[0]
                # flip sync value to be active high
                x.sync = np.invert(x.sync.astype(bool)).astype(x.sync.dtype)
                # TODO: convert accelerometer
                # TODO: convert gps
                # convert distance from millimeters to meters
                x.distance /= 1000
            records.append(x)
    return records


def _get_bicycle_records(index=None):
    # load calibration data
    calibration_path = os.path.join(os.path.dirname(__file__),
                                    '..', r'config.p')
    with open(calibration_path, 'rb') as f:
        calibration = pickle.load(f)

    records = []
    if index is None:
        index = slice(None)
    else:
        index = slice(index, index + 1)

    for filename in BICYCLE_RECORD_FILES[index]:
        r = load_file(filename, calibration['convbike'])
        records.append(r)
    return records


class Record(object):
    kinds = ('lidar', 'bicycle')

    def __init__(self, lidar_record, bicycle_record):
        assert hasattr(lidar_record, 'distance')
        assert hasattr(bicycle_record, 'speed')

        self.lidar = LidarRecord(lidar_record)
        self.bicycle = bicycle_record
        self.synced = None
        self._trial = None
        self._trial_range_index = None
        self.trial = None

        self.offset = {} # applied to bicycle signals

        dt = np.diff(self.bicycle.time)
        self.bicycle_period = self._nearest_millisecond(dt.mean())

    def sync(self):
        if self.synced is None:
            period = self.bicycle_period
            a = SampledTimeSignal.from_record(self, 'lidar', 'sync', period)
            b = SampledTimeSignal.from_record(self, 'bicycle', 'sync', period)

            sync_offset = a.sync_offset(b)
            time_offset = self.bicycle.time[0] - self.lidar.time[0]
            self.bicycle.time += sync_offset - time_offset

            self.synced = sync_offset
        return self.synced

    @staticmethod
    def _nearest_millisecond(x):
        return np.round(x, 3)

    @staticmethod
    def _cheby1_lowpass_filter(x, fc, fs):
        order = 5
        apass = 0.001 # dB

        wn = fc / (0.5*fs)
        b, a = scipy.signal.cheby1(order, apass, wn)
        return scipy.signal.filtfilt(b, a, x)

    def _calculate_trials2(self, missing_sync=None,
                           trial_mask=None,
                           lidar_bbmask=None,
                           offset_calibration=True):
        """Calculate trials from bicycle and lidar data using sync signals.
        The braking and overtaking event is calculated.

        This is used with data collected in Gothenburg April 2018.

        Parameters:
        missing_sync: array_like of approximate time of missing sync signals
        trial_mask: int or slice or array_like, any valid numpy array index of
                    trial indices to ignore
        lidar_bbmask: dict, keywords to pass to lidar.cartesian() for a bounding
                      box to exclude during event detection. Note that this is
                      applied to all trials in a record.
        offset_calibration: bool, use data when sync is active to calibrate
                            zero offset for bicycle IMU signals.

        Notes:
        All elements in missing_sync are treated as timestamps for rising edges.
        The corresponding falling edge occurs 1 sample later.

        Example:
        > r = Record(lidar_record, bicycle_record)
        > r.sync()
        > r._calculate_trials2(
              missing_sync=[650],
              skip_trial=0)
        """
        if offset_calibration:
            index = self.bicycle.sync.astype(int)
            for name in self.bicycle.dtype.names:
                if name.startswith(('accelerometer', 'gyroscope')):
                    offset_value = -self.bicycle[name][index].mean()
                    self.bicycle[name] += offset_value
                    self.offset[name] = offset_value

        edges = np.diff(self.bicycle.sync.astype(int))
        rising = np.where(edges > 0)[0]
        falling = np.where(edges < 0)[0]

        if missing_sync is not None:
            def insort(a, value):
                return np.insert(a, np.searchsorted(a, value), value)

            for m in missing_sync:
                i0 = np.where(self.bicycle.time >= m)[0][0]

                # add in missing sync signals
                rising = insort(rising, i0)
                falling = insort(falling, i0 + 1)

        # we expect to always have paired edges for the sync signal
        assert len(rising) == len(falling)

        # we want the data after a sync falling edge and before a rising edge
        trial_indices = zip(falling[:-1], rising[1:])

        if trial_mask is not None:
            # apply a mask to the indices
            selectors = np.ones(len(rising) - 1, dtype=int)
            selectors[trial_mask] = 0
            trial_indices = itertools.compress(trial_indices, selectors)

        trials = []
        for i0, i1 in trial_indices:
            i1 += 1 # add extra index to improve viewing of braking in plots
            time0 = self.bicycle.time[i0]
            time1 = self.bicycle.time[i1]
            j0 = self.lidar.frame_index(time0)[0]
            j1 = self.lidar.frame_index(time1)[0]

            # allow one extra end frame for lidar data in case it is necessary
            # for interpolation
            bicycle_data = self.bicycle[i0:i1]
            lidar_data = self.lidar[j0:j1 + 1]

            trials.append(Trial2(self,
                                 bicycle_data,
                                 lidar_data,
                                 self.bicycle_period,
                                 bbmask=lidar_bbmask))

        if len(trials) != 18:
            msg = ('Unexpected number of trials (got {}, not {}).' +
                    ' Consider using \'trial_mask\' to mask specific ' +
                    'trials.').format(len(trials), 18)
            warnings.warn(msg, UserWarning)
        self.trials = trials

    def _calculate_trial_ranges(self, trial_number):
        """In a trial, we normally observe 3 phases. We describe each phase as:
        1. Subject moves from the LIDAR/obstacle to path start
        2. Subject moves from path start to path end
        3. Subject moves from path end to the LIDAR/obstacle

        Each phase corresponds to a bump in the speed signal. Phase 2 is
        extracted by the following method:
        1. Apply a low-pass filter to the speed signal.
        2. Calculate local extrema of speed signal for the entire trial.
           This is denoted as RANGE0.
        3. Pick local maxima from RANGE0 that exceed the threshold RANGE1_LIMIT.
           The time spanned by these local maxima denote RANGE1.
        4. Pick local minima within RANGE1 and less than
           RANGE2_PERCENT*min(maxima_RANGE1) and RANGE2_LIMIT. The time
           spanned by these local minima denote RANGE2.
        5. Pick local maxima within RANGE2. The time spanned by these local
           maxima denote RANGE3.
        6. Find the local minima of RANGE2 closest in time before and after
           RANGE3.
        """
        RANGE1_LIMIT = 1 # [kph]
        RANGE2_LIMIT = 4 # [kph]
        RANGE2_PERCENT = 0.9 # [percent]

        # filtered speed
        fs = 1/self.bicycle_period
        v = self._cheby1_lowpass_filter(self._trial[trial_number].speed,
                                        0.08, fs)

        # range0 extrema
        r0_minima = scipy.signal.argrelextrema(v, np.less)[0]
        r0_maxima = scipy.signal.argrelextrema(v, np.greater)[0]
        r0 = np.concatenate((r0_minima, r0_maxima))

        r1_maxima = np.array([i for i in r0_maxima if v[i] > RANGE1_LIMIT])
        if len(r1_maxima) < 1:
            print('Unable to determine range 1')
            return (r0, None, None, None, None)

        a = min(RANGE2_PERCENT * v[r1_maxima].min(), RANGE2_LIMIT)
        r2_minima = np.array([i for i in r0_minima
                              if ((i > r1_maxima[0]) and
                                  (i < r1_maxima[-1]) and
                                  (v[i] < a))])
        if len(r2_minima) < 1:
            print('Unable to determine range 2')
            return (r0,
                    r1_maxima,
                    None,
                    None,
                    None)

        ia = r1_maxima > r2_minima[0]
        ib = r1_maxima < r2_minima[-1]
        r3_maxima = r1_maxima[ia & ib]

        b = None
        c = None
        for i in r2_minima:
            if i < r3_maxima[0]:
                b = i
            if i > r3_maxima[-1]:
                c = i
                break
        # Special case to fix range 4 for rider 3, trial 0.
        for i in r2_minima:
            if i > b and i < c:
                b = i
                break;
        r4 = np.array([b, c])

        return (r0,
                r1_maxima,
                r2_minima,
                r3_maxima,
                r4)

    def _calculate_trials(self):
        rising_edges = np.where(np.diff(self.bicycle.sync) > 0)[0]
        trials = zip(rising_edges, rising_edges[1:])
        t = self.bicycle.time

        # filter out trials that are too short
        MINIMUM_TRIAL_DURATION = 30 # seconds
        self._trial = [self.bicycle[a:b]
                       for a, b in trials
                       if (t[b] - t[a]) > MINIMUM_TRIAL_DURATION]

        trial_range_index = []
        trials = []
        for i in range(len(self._trial)):
            time_ranges = self._calculate_trial_ranges(i)
            if time_ranges[4] is not None:
                trial = self._trial[i][slice(*time_ranges[4])]
                active_range = self._active_trial_range(trial)
                trial_data = trial[slice(*active_range)]
            else:
                # missing/problematic velocity signal for rider 0 trial {0, 1}
                # use manually calculated values calculated for an
                # unsynchronized record

                # assume this error only occurs for rider 0
                trial = self._trial[i]
                t0 = self.bicycle.time[0]
                if i == 0:
                    index = (trial.time > (80 + t0)) & (trial.time < (95 + t0))
                elif i == 1:
                    index = ((trial.time > (270 + t0)) &
                             (trial.time < (280 + t0)))
                trial_data = trial[index]

            trial_range_index.append(time_ranges)
            trials.append(Trial(trial_data, self.bicycle_period))

        self._trial_range_index = trial_range_index
        self.trial = trials

    def _active_trial_range(self, trial):
        """Extract the range of a trial where the participant is active. This
        removes the parts of the start and end of a trial and may not capture
        initial acceleration nor final deceleration.
        """
        MIN_SPEED = 2.8 # m/s

        # filter speed
        fs = 1/self.bicycle_period
        v = self._cheby1_lowpass_filter(trial.speed, 0.5, fs)

        edges = np.diff((v > MIN_SPEED).astype(int))
        edge_index = np.where(edges)[0]
        edge_type = edges[edge_index] # rising (1) or falling (-1)

        n = len(edge_type)
        assert n > 0 # verify the signal exceeds MIN_SPEED

        # go through observed cases
        if n == 1 and edge_type[0] == -1:
            # single falling edge in the second half of trial
            # set rising edge to the first sample
            assert edge_index[0] > n/2
            index = np.insert(edge_index, 0, 0)
        elif n == 2 and edge_type[0] == 1 and edge_type[1] == -1:
            # normal case with single rising edge and single falling edge
            index = edge_index
        elif n == 3 and edge_type[0] == -1 and edge_index[0] < 100:
            # extra falling edge at the start of the trial
            assert edge_type[1] == 1
            assert edge_type[2] == -1
            index = edge_index[1:]
        else:
            # some other non-handled case occurs
            raise NotImplementedError
        return index

    def plot_timing(self, ax=None, **kwargs):
        def plot_two(ax, data, color, label):
            call = lambda f: tuple(map(f, self.kinds))

            if callable(data):
                data = call(data)
            if callable(color):
                color = call(color)
            if callable(label):
                label = call(label)

            args = zip(data, color, label)
            return [ax.plot(*d, color=c, label=l) for d, c, l in args]

        if ax is None:
            _, ax = plt.subplots(2, 1, sharex=True, **kwargs)

        colors = sns.color_palette('Paired', 10)
        colors_iter = iter(colors)

        def reduced_signal(t, x):
            xr, index = reduce_runs(x)
            return t[index], xr

        def get_sample_time(key):
            time = getattr(self, key)['time']
            sample_time = self._nearest_millisecond(np.diff(time))
            return reduced_signal(time[1:], sample_time)
        plot_two(ax[0],
                 get_sample_time,
                 colors_iter,
                 lambda k: '{} sample time'.format(k))
        ax[0].set_xlabel('time [s]')
        ax[0].set_ylabel('last sample time [s]')
        ax[0].legend()

        def sync_func(key):
            time = getattr(self, key)['time']
            sync = getattr(self, key)['sync']
            return reduced_signal(time, sync)
        plot_two(ax[1],
                 sync_func,
                 colors_iter,
                 lambda k: '{} sync button'.format(k))
        ax[1].set_xlabel('time [s]')
        ax[1].set_ylabel('button status')
        ax[1].legend()
        return ax

    def plot_trial_range_calculation(self, trial_number, ax=None, **kwargs):
        if ax is None:
            _, ax = plt.subplots(**kwargs)

        colors = sns.color_palette('Paired', 10)

        ran = self._trial_range_index[trial_number]
        trial = self._trial[trial_number]
        v = self._cheby1_lowpass_filter(trial.speed,
                                        0.08,
                                        1/self.bicycle_period)

        ax.plot(trial.time, trial.speed, label='speed',
                alpha=0.5, color=colors[0], zorder=0)
        ax.plot(trial.time, v, label='speed, cheby1 low pass',
                linewidth=3, color=colors[2], zorder=1)
        try:
            # use trial() method to get data sliced to valid range
            valid_trial = self.trial(trial_number)
            ax.plot(valid_trial.time, valid_trial.speed,
                    label='speed (valid range)',
                    color=colors[1], zorder=0)
        except TypeError:
            pass

        mt = 'X' # markertype
        ms = 10 # markersize
        ax.plot(trial.time[ran[0]], v[ran[0]], mt, label='range 0 extrema',
                markersize=ms, color=colors[3])
        if ran[1] is not None:
            ax.plot(trial.time[ran[1]], v[ran[1]], mt, label='range 1 maxima',
                    markersize=ms, color=colors[7])
        if ran[2] is not None:
            ax.plot(trial.time[ran[2]], v[ran[2]], mt, label='range 2 minima',
                    markersize=ms, color=colors[5])
        if ran[4] is not None:
            ax.plot(trial.time[ran[4]], v[ran[4]], mt, label='range 4 minima',
                    markersize=ms, color=colors[9])
            ax.axvspan(trial.time[ran[4]][0], trial.time[ran[4]][-1],
                       label='range 4',
                       alpha=0.5, color=colors[8])

        ax.set_xlabel('time [s]')
        ax.set_ylabel('speed [m/s]')
        ax.legend()
        return ax

    def plot_trial_detection(self, ax=None, **fig_kw):
        if ax is None:
            fig, ax = plt.subplots(3, 1, sharex=True, **fig_kw)
        else:
            assert len(ax) == 3
            fig = ax[0].get_figure()

        def apply_clumps_index(shape, clumps):
            index = np.zeros(shape, dtype=bool)
            for c in clumps:
                index[c] = True
            return index

        i = 0
        colors = sns.color_palette('Paired', 12)
        for tr in self.trials:
            t0, t1 = tr.event.bicycle.time[[0, -1]]
            ax[0].axvspan(t0, t1, color=colors[5], alpha=0.3)
            ax[1].axvspan(t0, t1, color=colors[5], alpha=0.3)
            ax[2].axvspan(t0, t1, color=colors[5], alpha=0.3)

            # alternate colors between trials
            i = i ^ 1
            ax[0].plot(tr.bicycle.time, tr.bicycle.speed, color=colors[i])

            shape = tr.lidar.time.shape
            ax[1].plot(tr.lidar.time,
                       apply_clumps_index(shape,
                                          tr.event_detection.valid_clumps),
                       color=colors[i])

            # cyclist entry
            ax[2].plot(tr.lidar.time,
                       apply_clumps_index(shape,
                                          tr.event_detection.entry_clumps),
                       color=colors[6])

            # cyclist exit
            ax[2].plot(tr.lidar.time,
                       apply_clumps_index(shape,
                                          tr.event_detection.exit_steer_clumps),
                       linestyle='--',
                       color=colors[8])
            ax[2].plot(tr.lidar.time,
                       apply_clumps_index(shape,
                                          tr.event_detection.exit_brake_clumps),
                       linestyle='-.',
                       color=colors[8])

        ax[1].plot(self.bicycle.time, self.bicycle.sync, color=colors[3])
        ax[2].plot(self.bicycle.time, self.bicycle.sync, color=colors[3])

        ax[0].set_ylabel('velocity')
        ax[1].set_ylabel('valid bbox detection')
        ax[2].set_ylabel('entry/exit bbox detection')
        ax[2].set_xlabel('time')

        return fig, ax


def load_records(sync=False, index=None):
    records = [Record(l, b) for l, b in zip(_get_lidar_records(index=index),
                                            _get_bicycle_records(index=index))]
    for r in records:
        if sync:
            r.sync()
        r._calculate_trials()
    return records


class TimeSignal(object):
    def __init__(self, time, signal):
        assert(isinstance(time, np.ndarray))
        assert(isinstance(signal, np.ndarray))
        assert(time.shape == signal.shape)
        self.time = time
        self.signal = signal
        self.time.flags.writeable = False
        self.signal.flags.writeable = False
        self.__mutable = False

    def shift_time(self, shift):
        if self.__mutable:
            self.time.flags.writeable = True
            self.time += shift
            self.time.flags.writeable = False
            return True
        return False


class SampledTimeSignal(TimeSignal):
    def __init__(self, time, signal, period=None):
        super(SampledTimeSignal, self).__init__(time, signal)
        self.period = np.diff(time).mean()
        if period is not None:
            npt.assert_almost_equal(self.period, period)

        # allow methods to modify time and signal data
        self.__mutable = True

    def shift_time_index(self, shift):
        return self.shift_time(shift * self.period)

    def __getitem__(self, key):
        period = self.period
        if key.step is not None:
            period *= key.step

        signal_slice = SampledTimeSignal(self.time[key], self.signal[key], period)
        signal_slice.__mutable = False
        return signal_slice

    @classmethod
    def from_record(cls, record, kind, signal, period):
        """Create a SampledTimeSignal from a specific signal in a Record. This
        will resample the signal with the given period by interpolation.

        Parameters
        record: Record, source data
        kind: string, 'lidar' or 'bicycle'
        signal: string, name of signal
        period: float, resampled signal period
        """
        record_kind = getattr(record, kind)
        resampled_time = np.arange(0, record_kind['time'].max(), period)
        resampled_signal = np.interp(resampled_time,
                                     record_kind['time'],
                                     record_kind[signal])

        return cls(resampled_time, resampled_signal, period)

    def sync_offset(self, other):
        """Calculate the time offset of 'other' from 'self' by maximizing
        signal cross-correlation.

        Parameters:
        other: SampledTimeSignal

        Returns:
        offset: float, value in seconds

        Notes:
        self.period and other.period must be equal.
        """
        assert(isinstance(other, type(self)))
        npt.assert_almost_equal(self.period, other.period)

        time_offset = other.time[0] - self.time[0]

        # If other signal is longer, np.correlate() will swap arguments.
        if (other.signal.shape[0] > self.signal.shape[0]):
            return -other.sync_offset(self)

        sync_success_limit = 0.9 * self.signal.sum();

        c = np.correlate(self.signal, other.signal, mode='valid')
        index = c.argmax()

        if c[index] < sync_success_limit:
            # If synchronization failure, use slower 'full' mode
            c = np.correlate(self.signal, other.signal, mode='full')
            # indexing for full differs from valid
            time_offset += (len(other.time) - 1)*self.period
            index = c.argmax()

            if c[index] < sync_success_limit:
                raise ValueError(
                        'Unable to synchronize signals {}, {}',
                        self, other)

        return self.period*index - time_offset
